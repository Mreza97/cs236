{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1LvVU0u6fLY3QOEZhngeZCsLr9ES6bk3D",
      "authorship_tag": "ABX9TyOFAWFVUkItYdki1dBFSVf1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpgit12/cs236/blob/main/AudioData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdApfcEv-2Mo"
      },
      "source": [
        "https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-eHHvejbRz2"
      },
      "source": [
        "!pip install music21 --upgrade\n",
        "!pip install midi2audio\n",
        "!sudo apt-get install fluidsynth\n",
        "!sudo apt-get install fluid-soundfont-gm\n",
        "!mkdir -p ~/.fluidsynth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGQ-Z47pOPcr"
      },
      "source": [
        "#import mido as m\n",
        "import music21 as m21\n",
        "from midi2audio import FluidSynth\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL92n_KRtCAk"
      },
      "source": [
        "sample_file = glob.glob('project/maestro-v3.0.0/2017/*.midi')[1]\n",
        "sample_file = sample_file[len('project/maestro-v3.0.0/'):]\n",
        "sample_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCBDPyTvtv7v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLZY0xlLsfKI"
      },
      "source": [
        "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\").midi_to_audio(sample, '/content/project/output.wav')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgCKBikIuQ3c"
      },
      "source": [
        "mf.ticksPerSecond"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA8dolMqfXG8"
      },
      "source": [
        "sample_file = '2017/MIDI-Unprocessed_081_PIANO081_MID--AUDIO-split_07-09-17_Piano-e_2_-02_wav--1.midi'\n",
        "mf = m21.midi.MidiFile()\n",
        "mf.open(f'project/maestro-v3.0.0/{sample_file}')\n",
        "mf.read()\n",
        "mf.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQUO93ht85b2"
      },
      "source": [
        "#rputtkammer@romans-mbp-2 2017 % soxi -d MIDI-Unprocessed_081_PIANO081_MID--AUDIO-split_07-09-17_Piano-e_2_-02_wav--1.wav \n",
        "#00:10:24.69\n",
        "wav_time_sec = 10*60+24+.69"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJDpj0pT6Uuq"
      },
      "source": [
        "midi_time_ticks = sum([ e.time for e in mf.tracks[1].events if e.isDeltaTime() ])\n",
        "midi_time_ticks / wav_time_sec\n",
        "\n",
        "# 960 ticks per second !!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ8hDsDqc4h9"
      },
      "source": [
        "mt = mf.tracks[1]\n",
        "ev = mt.events[0]\n",
        "\n",
        "assert len(mf.tracks) == 2\n",
        "print(\"event types\", set([e.type for e in mt.events]))\n",
        "\n",
        "# speed is set by track and by SET_TEMPO meta events - not expecting these here...\n",
        "\n",
        "print(\"ticksPerQuarterNote\", mf.ticksPerQuarterNote)\n",
        "print(\"ticksPerSecond\", mf.ticksPerSecond)\n",
        "\n",
        "# default bpm is 120, or 500000 ticks per min\n",
        "\n",
        "# let's calculate total ticks for this song\n",
        "\n",
        "track_length = [sum([e.time for e in t.events if e.isDeltaTime()]) for t in mf.tracks ]\n",
        "print(\"Track Lengths:\", track_length)\n",
        "\n",
        "# can we assume 2 tracks, with only the second one relevant?\n",
        "\n",
        "assert track_length[0]==1\n",
        "total_ticks = track_length[1]\n",
        "total_ticks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2zanpwzsem8"
      },
      "source": [
        "sample_dir = \"project/maestro-v3.0.0\"\n",
        "df = pd.read_csv(f\"{sample_dir}/maestro-v3.0.0.csv\")\n",
        "df_rec = df[df.midi_filename == sample_file]\n",
        "df_rec\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBfh4abgRtb1"
      },
      "source": [
        "# is this the right ticks per minute, or is it actually 60000\n",
        "\n",
        "total_sec = df_rec.duration.iloc[0]\n",
        "ticks_per_min = total_ticks / total_sec * 60\n",
        "#ticks_per_min\n",
        "\n",
        "beats_per_min = ticks_per_min / mf.ticksPerQuarterNote\n",
        "print(\"ticks_per_min\", ticks_per_min)\n",
        "print(\"beats_per_min\", beats_per_min)\n",
        "\n",
        "# maybe it's actually 60000 ticks per minut and 125 beats per minute?\n",
        "total_sec / 125 * 60000\n",
        "# calculate ticks per beat then ...\n",
        "total_ticks / total_sec * 60 / 120\n",
        "\n",
        "# I think the files are using 120 bpm - that works out nicely\n",
        "beats_per_min = 120\n",
        "ticks_per_min = mf.ticksPerQuarterNote * beats_per_min\n",
        "ticks_per_beat = mf.ticksPerQuarterNote\n",
        "ticks_per_sec = ticks_per_min/60\n",
        "\n",
        "ticks_per_min, beats_per_min, ticks_per_beat, ticks_per_sec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFNaYtcES7ZN"
      },
      "source": [
        "# let's get a random chunk from the audio & midi file\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "sample_duration_sec_minmax = np.array([2,10])\n",
        "\n",
        "sample_duration = random.randint(*(np.minimum(sample_duration_sec_minmax, df_rec.duration.iloc[0])*ticks_per_sec).astype(np.int32))\n",
        "sample_offset = random.randint(0, (int)(df_rec.duration.iloc[0]*ticks_per_sec-sample_duration))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVk8f70lEtn3"
      },
      "source": [
        "\n",
        "print(f\"sample {sample_duration/ticks_per_sec} starting at offset {sample_offset/ticks_per_sec}\")\n",
        "\n",
        "import librosa as lr\n",
        "\n",
        "y, sr = lr.load(f\"{sample_dir}/{df_rec.audio_filename.iloc[0]}\", sr=44100, mono=True, offset=sample_offset/ticks_per_sec,\n",
        "                duration=sample_duration/ticks_per_sec)\n",
        "\n",
        "import soundfile as sf\n",
        "\n",
        "sf.write('project/sample_wav.wav', data=y, samplerate=sr, subtype='PCM_24')\n",
        "!ls -l project/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka0E5Ouvb-mC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHlnsEiPJkZ3"
      },
      "source": [
        "import IPython\n",
        "display(IPython.display.Audio(y, rate=sr))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW3GC8TKPynn"
      },
      "source": [
        "\n",
        "# looks like everything is in track 1, channel 1\n",
        "\n",
        "ticks_start, ticks_end = sample_offset, sample_duration+sample_offset\n",
        "print(f\"looking for {ticks_start} to {ticks_end} with length {(ticks_end-ticks_start)/ticks_per_sec}\")\n",
        "time_curr, time_last_event = 0, ticks_start\n",
        "samples = []\n",
        "nsamples = []\n",
        "\n",
        "nsamples.append(m21.midi.DeltaTime(track=None, time=0, channel=1))\n",
        "pce = m21.midi.MidiEvent(ntrack, type=m21.midi.ChannelVoiceMessages.PROGRAM_CHANGE, channel=1)\n",
        "pce.parameter1 = 0\n",
        "nsamples.append(pce)\n",
        "\n",
        "for e in mf.tracks[1].events:\n",
        "    if e.isDeltaTime():\n",
        "        time_curr = time_curr + e.time\n",
        "        if time_curr > ticks_end:\n",
        "            print(\"reached end\", ticks_end)\n",
        "            break\n",
        "    else:\n",
        "        assert e.time == 0\n",
        "    if time_curr >= ticks_start:\n",
        "        if e.type == m21.midi.ChannelVoiceMessages.NOTE_ON:\n",
        "\n",
        "            # insert delta time\n",
        "            ne = m21.midi.DeltaTime(track=None, time=time_curr-time_last_event, channel=1)\n",
        "            nsamples.append(ne)\n",
        "\n",
        "            # insert note on\n",
        "            ne = m21.midi.MidiEvent(track=None, type=m21.midi.ChannelVoiceMessages.NOTE_ON, time=0, channel=1)\n",
        "            ne.pitch = e.pitch\n",
        "            ne.velocity = e.velocity\n",
        "            ne.parameter1 = e.parameter1\n",
        "            ne.parameter2 = e.parameter2\n",
        "            nsamples.append(ne)\n",
        "\n",
        "            time_last_event = time_curr\n",
        "\n",
        "        elif e.isDeltaTime():\n",
        "            pass\n",
        "        elif e.type == m21.midi.ChannelVoiceMessages.CONTROLLER_CHANGE and e.parameter1 == 64:\n",
        "            pass\n",
        "        else:\n",
        "            pass\n",
        "            #print(f\"warning, skipping type {e.type}\")\n",
        "    else:\n",
        "        #print(f\"skipping initial {e} at {time_curr}\")\n",
        "        pass\n",
        "\n",
        "last_delta = max(ticks_end - time_last_event, 0)\n",
        "nsamples.append(m21.midi.DeltaTime(track=None, time=last_delta, channel=1))\n",
        "time_last_event = time_last_event + last_delta\n",
        "\n",
        "eot = m21.midi.MidiEvent(ntrack, type=m21.midi.MetaEvents.END_OF_TRACK)\n",
        "eot.data = b''\n",
        "nsamples.append(eot)\n",
        "\n",
        "print(f\"total time {time_last_event-ticks_start} {(time_last_event-ticks_start)/ticks_per_sec}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVrCFE25Z7IU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6g9OMuelmD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWY8XmoJh_eR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1no8ZVWWX90"
      },
      "source": [
        "!rm -f project/sample.midi\n",
        "\n",
        "sf = m21.midi.MidiFile()\n",
        "sf.format = 1\n",
        "sf.ticksPerQuarterNote = ticks_per_beat\n",
        "sf.ticksPerSecond = None\n",
        "sf.tracks = [ ntrack ]\n",
        "sf.tracks[0].setChannel(1)\n",
        "sf.tracks[0].events = list(nsamples)\n",
        "sf.tracks[0].updateEvents()\n",
        "\n",
        "sf.open(f'project/sample.midi', 'wb')\n",
        "sf.write()\n",
        "sf.close()\n",
        "\n",
        "!rm -f project/sample.wav\n",
        "!ls -al project/sample.*\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH25cdDpUwiI"
      },
      "source": [
        "#FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\").midi_to_audio('project/sample.midi', '/content/project/sample.wav')\n",
        "!fluidsynth -O s24 -L 1 -F project/sample_midi_to_wav.wav /usr/share/sounds/sf2/FluidR3_GM.sf2 project/sample.midi\n",
        "!ls -al project/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qtvx_5OonAM"
      },
      "source": [
        "display(IPython.display.Audio('project/sample_midi_to_wav.wav'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "innyE2lTck8v"
      },
      "source": [
        "display(IPython.display.Audio('project/sample_wav.wav'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJRnlm-EOJr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77_5aBwA7QwB"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "def showmfcc(mfccs):\n",
        "    fig, ax = plt.subplots()\n",
        "    img = lr.display.specshow(mfccs, x_axis='time', ax=ax)\n",
        "    fig.colorbar(img, ax=ax)\n",
        "    ax.set(title='MFCC')\n",
        "    return fig\n",
        "\n",
        "y1, sr1 = lr.load(f\"project/sample.wav\", sr=None, mono=True)\n",
        "mfccs = lr.feature.mfcc(y=y1, sr=sr, n_mfcc=40)\n",
        "fig = showmfcc(mfccs)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2A5zVdeE9fh"
      },
      "source": [
        "y2, sr2 = lr.load(f\"project/output.wav\", sr=None, mono=True)\n",
        "mfccs = lr.feature.mfcc(y=y2, sr=sr, n_mfcc=40)\n",
        "fig = showmfcc(mfccs)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6FEU9tNR2nq"
      },
      "source": [
        "display(IPython.display.Audio(y1, rate=sr1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i6e3TrESK2q"
      },
      "source": [
        "display(IPython.display.Audio(y2, rate=sr))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yr1hafLSK77"
      },
      "source": [
        "display(IPython.display.Audio(y1+y2, rate=sr2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJI-W76ulO7t"
      },
      "source": [
        "archive_root='/content/data'\n",
        "archive_url='https://storage.googleapis.com/paustian_cs236/maestro-v3.0.0-2017-v1.zip'\n",
        "archive_name='maestro-v3.0.0-2017-v1.zip'\n",
        "!test -d {archive_root} || mkdir -p {archive_root}\n",
        "!test -f {archive_root}/{archive_name} || ( cd {archive_root} && wget --no-cache \"{archive_url}\" ; )\n",
        "!test -d {archive_root}/maestro-v3.0.0 && test -f {archive_root}/maestro-v3.0.0/maestro-v3.0.0.csv || ( cd {archive_root} && unzip -qo {archive_name} ; )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC-FDpt0SXBC"
      },
      "source": [
        "from dataclasses import dataclass, field\n",
        "import numpy as np\n",
        "from typing import List\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import music21 as m21\n",
        "import warnings\n",
        "\n",
        "# Alright, time to wrap this up....\n",
        "\n",
        "# First, our data is stored like this [DATA_LOCATION]/[YEAR]/file.*\n",
        "# and [DATA_LOCATION]/maestro-v3.0.0.csv has all relevant meta data\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MaestroDataConfig:\n",
        "    root_dir: str = '/content/data/maestro-v3.0.0'\n",
        "    meta_csv: str = 'maestro-v3.0.0.csv'\n",
        "    seed: int = None\n",
        "    subset: float = 1\n",
        "    years: list = field(default_factory=list)\n",
        "    midi_ticks_per_sec = 960\n",
        "    midi_beats_per_min = 120\n",
        "    sec_per_sample = [ 2, 5 ]\n",
        "    sr = 44100\n",
        "    n_fft=2048\n",
        "    hop_length=1024         # sr / hop_length = resolution (MFCCs per sec,) 43\n",
        "    win_length=1024\n",
        "    n_mels=128              # number of samples per time step\n",
        "    #n_mfcc=20\n",
        "    power=2\n",
        "\n",
        "class MaestroData:\n",
        "\n",
        "    def __init__(self, config=MaestroDataConfig(), random_state=None):\n",
        "        self.config = config\n",
        "        self.random_state = np.random.RandomState(seed=self.config.seed)\n",
        "        self.df = pd.read_csv(f\"{self.config.root_dir}/{self.config.meta_csv}\")\n",
        "        self.df = self.df.sample(frac=1, random_state=self.random_state)\n",
        "        if self.config.subset != 1.0:\n",
        "            self.df = self.df.groupby(['year','split'], as_index=False).apply(lambda g: g.sample((int)(self.config.subset*len(g)), random_state=self.random_state))\n",
        "        if self.config.years:\n",
        "            self.df = self.df[self.df.year.isin(self.config.years)]\n",
        "    def get_data(self, train=False, test=False, validation=False):\n",
        "        dataset = np.array([train, test, validation]) != 0\n",
        "        filter = np.array(['train', 'test', 'validation'])[dataset]\n",
        "        records = data.df[data.df.split.isin(filter)]\n",
        "        return records\n",
        "    def load_mfccs(self, dr, offset_sec, duration_sec):\n",
        "        wavfile = f\"{self.config.root_dir}/{dr.audio_filename}\"\n",
        "        y, sr = librosa.load(wavfile, sr=self.config.sr, mono=True, offset=offset_sec, duration=duration_sec)\n",
        "        mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=self.config.n_fft, hop_length=self.config.hop_length, win_length=self.config.win_length, n_mels=self.config.n_mels, power=self.config.power)\n",
        "        #mel_spect = librosa.power_to_db(spect, ref=np.max) - should be included with power=2 above ...\n",
        "        return mel_spect\n",
        "    def create_midi_file(self, dr, offset_ticks, duration_ticks):\n",
        "        events, remaining_ticks = self.load_midi_events(dr, offset_ticks, duration_ticks)\n",
        "        events.insert(0, m21.midi.DeltaTime(track=None, time=0, channel=1))\n",
        "        events.insert(1, m21.midi.MidiEvent(ntrack, type=m21.midi.ChannelVoiceMessages.PROGRAM_CHANGE, channel=1))\n",
        "        events[1].parameter1 = 0\n",
        "        events.append(m21.midi.DeltaTime(track=None, time=remaining_ticks, channel=1))\n",
        "        events.append(m21.midi.MidiEvent(ntrack, type=m21.midi.MetaEvents.END_OF_TRACK))\n",
        "        events[-1].data = b''\n",
        "\n",
        "        sf = m21.midi.MidiFile()\n",
        "        sf.format = 1\n",
        "        sf.ticksPerQuarterNote = self.config.ticks_per_beat\n",
        "        sf.ticksPerSecond = self.config.ticks_per_sec\n",
        "        sf.tracks = [ ntrack ]\n",
        "        sf.tracks[0].setChannel(1)\n",
        "        sf.tracks[0].events = list(nsamples)\n",
        "        sf.tracks[0].updateEvents()\n",
        "\n",
        "        sf.open(f'project/sample.midi', 'wb')\n",
        "        sf.write()\n",
        "        sf.close()\n",
        "\n",
        "    def load_midi_events(self, dr, offset_ticks, duration_ticks):\n",
        "        midifile = f\"{self.config.root_dir}/{dr.midi_filename}\"\n",
        "        mf = m21.midi.MidiFile()\n",
        "        mf.open(midifile)\n",
        "        mf.read()\n",
        "        mf.close()\n",
        "\n",
        "        ticks_end = int(offset_ticks + duration_ticks)\n",
        "        ticks_curr, ticks_last_event = 0, int(offset_ticks)\n",
        "        events = []\n",
        "\n",
        "        for e in mf.tracks[1].events:\n",
        "            if e.isDeltaTime():\n",
        "                ticks_curr = ticks_curr + e.time\n",
        "                if ticks_curr > ticks_end:\n",
        "                    break\n",
        "            else:\n",
        "                assert e.time == 0 # assumptions ...\n",
        "            if ticks_curr >= offset_ticks:\n",
        "                if e.type == m21.midi.ChannelVoiceMessages.NOTE_ON:\n",
        "                    # insert delta time\n",
        "                    ne = m21.midi.DeltaTime(track=None, time=ticks_curr-ticks_last_event, channel=1)\n",
        "                    events.append(ne)\n",
        "                    # insert note on\n",
        "                    ne = m21.midi.MidiEvent(track=None, type=m21.midi.ChannelVoiceMessages.NOTE_ON, time=0, channel=1)\n",
        "                    ne.pitch = e.pitch\n",
        "                    ne.velocity = e.velocity\n",
        "                    ne.parameter1 = e.parameter1\n",
        "                    ne.parameter2 = e.parameter2\n",
        "                    events.append(ne)\n",
        "                    ticks_last_event = ticks_curr\n",
        "                elif e.isDeltaTime():\n",
        "                    pass\n",
        "                elif e.type == m21.midi.ChannelVoiceMessages.CONTROLLER_CHANGE and e.parameter1 in (64,67):\n",
        "                    # pedals\n",
        "                    pass\n",
        "                elif e.type == m21.midi.ChannelVoiceMessages.PROGRAM_CHANGE and e.parameter1 in (0):\n",
        "                    # pedals\n",
        "                    pass\n",
        "                else:\n",
        "                    # assumptions ...\n",
        "                    warnings.warn(f\"unexpected event {e.type}, p1={e.parameter1}, p2={e.parameter2}, {e}\")\n",
        "                    \n",
        "        return events, max(ticks_end - ticks_last_event, 0)\n",
        "\n",
        "    def map_midi_events(self, events, remaining_ticks):\n",
        "        new_events = []\n",
        "        abs_time = 0\n",
        "        for e in events:\n",
        "            if e.isDeltaTime():\n",
        "                if e.time < 0 or e.time >=60000:\n",
        "                    print(f\"Warning, unexpected event time value {e.time}, {e}\")\n",
        "                if e.time > 0:\n",
        "                    new_events.append( min(abs_time, 59999) )\n",
        "                abs_time = abs_time + e.time\n",
        "            else:\n",
        "                if e.velocity<0 or e.velocity>127:\n",
        "                    print(f\"Warning, unexpected event velocity value {e.velocity}, {e}\")\n",
        "                else:\n",
        "                    new_events.append( 60000 + e.velocity )\n",
        "                if e.pitch<0 or e.pitch>127:\n",
        "                    print(f\"Warning, unexpected event pitch value {e.pitch}, {e}\")\n",
        "                else:\n",
        "                    new_events.append( 60128 + e.pitch )\n",
        "        if remaining_ticks > 0:\n",
        "            new_events.append(min(59999, remaining_ticks))\n",
        "        new_events.append(0)\n",
        "        return np.array(new_events)\n",
        "\n",
        "    def sample_record(self, dr):\n",
        "        duration_sec_range = np.array([self.config.sec_per_sample[0], min(self.config.sec_per_sample[1], dr.duration)])\n",
        "        duration_sec = self.random_state.rand() * (duration_sec_range[1]-duration_sec_range[0]) + duration_sec_range[0]\n",
        "        offset_sec = self.random_state.rand() * (dr.duration - duration_sec)\n",
        "        return offset_sec, duration_sec\n",
        "\n",
        "    def load_sample(self, dr, offset_sec, duration_sec):\n",
        "        mfccs = self.load_mfccs(dr, offset_sec, duration_sec)\n",
        "        events = self.load_midi_events(dr, offset_sec*self.config.midi_ticks_per_sec, duration_sec*self.config.midi_ticks_per_sec)\n",
        "        events = self.map_midi_events(*events)\n",
        "        return mfccs, events, (offset_sec, duration_sec)\n",
        "\n",
        "config = MaestroDataConfig(years=[2017], seed=2021)\n",
        "data = MaestroData(config)\n",
        "records = data.get_data(train=True)\n",
        "sample = data.sample_record(records.iloc[0])\n",
        "d = data.load_sample(records.iloc[0], *sample)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xnX3uxdHt7-"
      },
      "source": [
        "import torch\n",
        "\n",
        "class MaestroDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.records = data.get_data(train=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "        d = data.load_sample(self.records.iloc[idx], *self.data.sample_record(self.records.iloc[idx]))\n",
        "        return { 'mfcc' : d[0], 'midi' : d[1] }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKX6_dzuv1QL"
      },
      "source": [
        "dset = MaestroDataset(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD42kHG1Er0O"
      },
      "source": [
        "#!pip install line_profiler\n",
        "#%load_ext line_profiler\n",
        "#%lprun -f MaestroData.load_midi_events data.load_sample(records.iloc[0], *sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFpMPFh-Ik0Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7m6_jjgMVa_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPkTiJW5bAla"
      },
      "source": [
        "https://arxiv.org/abs/2010.07061\n"
      ]
    }
  ]
}